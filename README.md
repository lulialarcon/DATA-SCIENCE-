Proyecto de Predicción de Riesgo Crediticio Descripción del Proyecto Este proyecto implementa un sistema completo de predicción de riesgo crediticio utilizando técnicas de machine learning. El objetivo principal es predecir si un cliente realizará pagos a tiempo en sus créditos, basándose en características demográficas, financieras y de historial crediticio.

Estructura del Proyecto El proyecto está organizado en los siguientes componentes principales:

Análisis Exploratorio de Datos (EDA) En el archivo comprension_eda.py, realizo un análisis exhaustivo del conjunto de datos que incluye:
Carga y limpieza de datos

Análisis de distribuciones de variables

Detección y tratamiento de valores atípicos

Análisis de correlaciones entre variables

Visualizaciones para comprender las relaciones entre características

Ingeniería de Features El archivo ft_engineering.py contiene el procesamiento y transformación de datos:
Codificación de variables categóricas

Transformación de variables numéricas

Creación de nuevas características derivadas

Preparación de los datos para modelado

Entrenamiento y Evaluación de Modelos En model_training_evaluation.py, implemento:
Comparación de múltiples algoritmos de clasificación

Validación cruzada para evaluación robusta

Optimización de hiperparámetros

Generación de métricas de evaluación

Exportación del mejor modelo entrenado

Sistema de Monitoreo El archivo model_monitoring.py incluye:
Detección de data drift en producción

Monitoreo de calidad del modelo

Visualización de métricas de rendimiento

Alertas tempranas sobre degradación del modelo

API de Despliegue En model_deploy.py, implemento:
API REST con FastAPI para predicciones en tiempo real

Endpoints para predicción individual y por lotes

Sistema de monitoreo integrado

Documentación automática de la API

Características Técnicas Modelo Principal Utilizo XGBoost como modelo principal debido a su excelente rendimiento en problemas de clasificación con datos estructurados. El modelo fue entrenado con 25 características cuidadosamente seleccionadas y procesadas.

Arquitectura del Sistema Backend: FastAPI para la API REST

Modelo: XGBoost entrenado

Procesamiento: Pipeline de sklearn para consistencia

Monitoreo: Sistema de detección de drift

Despliegue: Contenedor Docker para fácil distribución

Métricas de Rendimiento El modelo logra las siguientes métricas de evaluación:

Accuracy: 95%

Precision: 96%

Recall: 99%

F1-Score: 97%

ROC-AUC: 88%

Requisitos del Sistema Dependencias Las dependencias están especificadas en requirements.txt e incluyen:

FastAPI y Uvicorn para la API

XGBoost para el modelo de machine learning

Pandas y NumPy para procesamiento de datos

Scikit-learn para preprocesamiento y métricas

Matplotlib y Seaborn para visualizaciones

Hardware Recomendado CPU: 2+ núcleos

RAM: 4GB mínimo

Almacenamiento: 1GB para modelo y datos

Instalación y Ejecución

Instalación Local bash pip install -r requirements.txt
Construcción de la Imagen Docker bash docker build -t riesgo-crediticio-api .
Ejecución del Contenedor bash docker run -p 8000:8000 riesgo-crediticio-api
Acceso a la API La API estará disponible en http://localhost:8000
Documentación: http://localhost:8000/docs

Health check: http://localhost:8000/health

Uso de la API Predicción Individual bash curl -X POST "http://localhost:8000/predict"
-H "Content-Type: application/json"
-d '{"data": [{...datos del cliente...}]}' Monitoreo de Data Drift bash curl -X POST "http://localhost:8000/monitoring"
-H "Content-Type: application/json"
-d '{"data": [{...datos de producción...}]}' Obtención de Métricas bash curl -X GET "http://localhost:8000/evaluation" Características del Conjunto de Datos El modelo utiliza 25 características que incluyen:

Información demográfica del cliente (edad, tipo laboral)

Características del crédito (monto, plazo, cuota)

Historial crediticio (puntaje, créditos vigentes, saldos)

Variables derivadas (logaritmos de ingresos y deudas)

Consideraciones de Implementación Preprocesamiento Todos los datos pasan por un pipeline de preprocesamiento que incluye:

Estandarización de variables numéricas

Codificación one-hot de variables categóricas

Transformaciones logarítmicas cuando es necesario

Manejo de valores faltantes

Validación Implemento múltiples estrategias de validación:

División train-test estratificada

Validación cruzada de 5 folds

Métricas específicas para clases desbalanceadas

Monitoreo en Producción El sistema incluye:

Detección automática de data drift

Alerta temprana de degradación del modelo

Métricas de calidad en tiempo real

Visualización de tendencias históricas

Mantenimiento y Actualización Reentrenamiento El modelo debe reentrenarse periódicamente con nuevos datos para mantener su precisión. Recomiendo:

Reentrenamiento mensual con datos actualizados

Validación con conjunto de holdout

Pruebas A/B antes de despliegue en producción

Monitoreo Continuo Establezco puntos de control para:

Verificación diaria de data drift

Monitoreo semanal de métricas de rendimiento

Auditoría mensual del pipeline completo

Limitaciones y Consideraciones Supuestos del Modelo Los datos de entrada siguen la misma distribución que los datos de entrenamiento

Las características están en el mismo formato y escala

No hay cambios estructurales en el proceso de otorgamiento de créditos

Áreas de Mejora Posibles mejoras futuras incluyen:

Incorporación de más fuentes de datos

Implementación de modelos ensemble

Sistema de explicabilidad del modelo (SHAP/LIME)

Automatización del reentrenamiento
